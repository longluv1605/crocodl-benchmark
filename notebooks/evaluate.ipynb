{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b4d8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import h5py\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fe5ef685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pose(kpts0, kpts1, K0, K1, thresh, conf=0.99999):\n",
    "    if len(kpts0) < 5:\n",
    "        return None\n",
    "\n",
    "    f_mean = np.mean([K0[0, 0], K1[1, 1], K0[0, 0], K1[1, 1]])\n",
    "    norm_thresh = thresh / f_mean\n",
    "\n",
    "    kpts0 = (kpts0 - K0[[0, 1], [2, 2]][None]) / K0[[0, 1], [0, 1]][None]\n",
    "    kpts1 = (kpts1 - K1[[0, 1], [2, 2]][None]) / K1[[0, 1], [0, 1]][None]\n",
    "\n",
    "    E, mask = cv2.findEssentialMat(\n",
    "        kpts0, kpts1, np.eye(3), threshold=norm_thresh, prob=conf,\n",
    "        method=cv2.RANSAC)\n",
    "\n",
    "    if E is None:\n",
    "        return None\n",
    "\n",
    "    best_num_inliers = 0\n",
    "    ret = None\n",
    "    for _E in np.split(E, len(E) / 3):\n",
    "        n, R, t, _ = cv2.recoverPose(\n",
    "            _E, kpts0, kpts1, np.eye(3), 1e9, mask=mask)\n",
    "        if n > best_num_inliers:\n",
    "            best_num_inliers = n\n",
    "            ret = (R, t[:, 0], mask.ravel() > 0)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def angle_error_mat(R1, R2):\n",
    "    cos = (np.trace(np.dot(R1.T, R2)) - 1) / 2\n",
    "    cos = np.clip(cos, -1., 1.)  # numercial errors can make it out of bounds\n",
    "    return np.rad2deg(np.abs(np.arccos(cos)))\n",
    "\n",
    "\n",
    "def angle_error_vec(v1, v2):\n",
    "    n = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "    return np.rad2deg(np.arccos(np.clip(np.dot(v1, v2) / n, -1.0, 1.0)))\n",
    "\n",
    "\n",
    "def compute_pose_error(T_0to1, est_pose):\n",
    "    R_gt = T_0to1[:3, :3]\n",
    "    t_gt = T_0to1[:3, 3]\n",
    "    R = est_pose[:3, :3]\n",
    "    t = est_pose[:3, 3]\n",
    "    error_t = angle_error_vec(t, t_gt)\n",
    "    error_t = np.minimum(error_t, 180 - error_t)  # ambiguity of E estimation\n",
    "    error_R = angle_error_mat(R, R_gt)\n",
    "    return error_t, error_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bc340d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_retrieval_pairs(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        pairs = []\n",
    "        for line in f:\n",
    "            pair = line.strip().split(\" \")\n",
    "            pairs.append(pair)\n",
    "    f.close()\n",
    "    return pairs\n",
    "\n",
    "def load_images(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        images = defaultdict(dict)\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"): continue\n",
    "            timestamp, sensor_id, image_path = line.strip().split(\", \")\n",
    "            images[image_path] = {\n",
    "                \"timestamp\": timestamp,\n",
    "                \"sensor_id\": sensor_id\n",
    "            }\n",
    "    return images\n",
    "\n",
    "def load_intrinsics(file_path):\n",
    "    sensors = defaultdict(dict)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"): continue\n",
    "            line = line.strip().split(\", \")\n",
    "            if len(line) < 6: continue\n",
    "            \n",
    "            sensor_id = line[0]\n",
    "            width, height = line[4:6]\n",
    "            fx, fy, cx, cy = line[6:]\n",
    "            K = np.array([\n",
    "                [fx, 0, cx],\n",
    "                [0, fy, cy],\n",
    "                [0, 0, 1],\n",
    "            ], dtype=float)\n",
    "            \n",
    "            sensors[sensor_id] = {\n",
    "                'K': K,\n",
    "                'width': int(width),\n",
    "                'height': int(height),\n",
    "            }\n",
    "    return sensors\n",
    "\n",
    "def load_rigs(file_path):\n",
    "    if file_path is None:\n",
    "        q = {'x': 0.0, 'y': 0.0, 'z': 0.0, 'w': 1.0}    # No rotate\n",
    "        t = {'x': 0.0, 'y': 0.0, 'z': 0.0}              # No translate\n",
    "        q_xyzw = np.array([q['x'], q['y'], q['z'], q['w']])\n",
    "        Q = Rotation.from_quat(q_xyzw).as_matrix()\n",
    "        T = np.array([t['x'], t['y'], t['z']])\n",
    "        \n",
    "        cam2rig = np.eye(4)\n",
    "        cam2rig[:3, :3] = Q\n",
    "        cam2rig[:3, 3] = T\n",
    "        \n",
    "        return {\n",
    "            'rig_sensors': {\n",
    "                'cam2rig': cam2rig,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    rigs = defaultdict(dict)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"): continue\n",
    "            line = line.strip().split(\", \")\n",
    "            \n",
    "            # rig_id = line[0].split(\"_\")[-1]\n",
    "            # sensor_id = line[1].split(\"/\")[-1]\n",
    "            \n",
    "            rig_id = line[0]\n",
    "            sensor_id = line[1]\n",
    "            q = {\n",
    "                'w': float(line[2]),\n",
    "                'x': float(line[3]),\n",
    "                'y': float(line[4]),\n",
    "                'z': float(line[5]),\n",
    "            }\n",
    "            t = {\n",
    "                'x': float(line[6]),\n",
    "                'y': float(line[7]),\n",
    "                'z': float(line[8]),\n",
    "            }\n",
    "            \n",
    "            q_xyzw = np.array([q['x'], q['y'], q['z'], q['w']])\n",
    "            Q = Rotation.from_quat(q_xyzw).as_matrix()\n",
    "            T = np.array([t['x'], t['y'], t['z']])\n",
    "            \n",
    "            cam2rig = np.eye(4)\n",
    "            cam2rig[:3, :3] = Q\n",
    "            cam2rig[:3, 3] = T\n",
    "            \n",
    "            rigs[rig_id][sensor_id] = {\n",
    "                'cam2rig': cam2rig,\n",
    "            }\n",
    "    return rigs\n",
    "\n",
    "def load_poses(file_path):\n",
    "    poses = defaultdict(dict)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"): continue\n",
    "            line = line.strip().split(\", \")\n",
    "            timestamp = line[0]\n",
    "            device_id = line[1]\n",
    "            \n",
    "            q = {\n",
    "                'w': float(line[2]),\n",
    "                'x': float(line[3]),\n",
    "                'y': float(line[4]),\n",
    "                'z': float(line[5]),\n",
    "            }\n",
    "            t = {\n",
    "                'x': float(line[6]),\n",
    "                'y': float(line[7]),\n",
    "                'z': float(line[8]),\n",
    "            }\n",
    "            \n",
    "            q_xyzw = np.array([q['x'], q['y'], q['z'], q['w']])\n",
    "            Q = Rotation.from_quat(q_xyzw).as_matrix()\n",
    "            T = np.array([t['x'], t['y'], t['z']])\n",
    "            pose = np.eye(4)\n",
    "            pose[:3, :3] = Q\n",
    "            pose[:3, 3] = T\n",
    "            poses[timestamp] = {\n",
    "                'pose': pose,\n",
    "                'device_id': device_id\n",
    "            }\n",
    "    return poses\n",
    "\n",
    "def load_keypoints(file_path):\n",
    "    \"\"\"\n",
    "    Load keypoints and descriptors from H5 file.\n",
    "    \n",
    "    Supports two structures:\n",
    "    \n",
    "    Structure 1 (ios_query):\n",
    "    - {session}/raw_data/{subsession}/images/{image_id}/\n",
    "      - keypoints, descriptors, scores, image_size\n",
    "    \n",
    "    Structure 2 (spot_query):\n",
    "    - {session}/raw_data/{subsession}/{camera}/{image_id}/\n",
    "      - keypoints, descriptors, scores, image_size\n",
    "    \n",
    "    Structure 3 (hl_query):\n",
    "    - {session}/raw_data/{subsession}/images/{camera}/{image_id}/\n",
    "      - keypoints, descriptors, scores, image_size\n",
    "    \n",
    "    Returns nested dicts with flexible structure based on hierarchy depth.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = defaultdict(dict)\n",
    "    \n",
    "    def recursive_load(group, result_key):\n",
    "        \"\"\"\n",
    "        Recursively traverse H5 group and load data when keypoints are found.\n",
    "        \"\"\"\n",
    "        # Check if this group contains keypoints (leaf node)\n",
    "        if 'keypoints' in group:\n",
    "            keypoints = np.array(group['keypoints'][:], dtype=np.int32)\n",
    "            descriptors = np.array(group['descriptors'][:], dtype=np.float32)\n",
    "            scores = np.array(group['scores'][:], dtype=np.float32)\n",
    "            image_size = np.array(group['image_size'][:], dtype=np.int32)\n",
    "            \n",
    "            results[result_key]['keypoints'] = keypoints\n",
    "            results[result_key]['descriptors'] = descriptors\n",
    "            results[result_key]['scores'] = scores\n",
    "            results[result_key]['image_size'] = image_size\n",
    "            return\n",
    "        \n",
    "        # If not leaf node, iterate through children\n",
    "        for key in group.keys():\n",
    "            item = group[key]\n",
    "            if isinstance(item, h5py.Group):\n",
    "                # Recurse into this group\n",
    "                recursive_load(item, f\"{result_key}{'/' if result_key != '' else ''}{key}\")\n",
    "    \n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        recursive_load(f, result_key=\"\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def load_matches(file_path):\n",
    "    \"\"\"\n",
    "    Load matching results from H5 file.\n",
    "    \n",
    "    Structure:\n",
    "    - Group for each query image\n",
    "      - Group for each map image\n",
    "        - matches0: matched indices in map image (-1 means no match)\n",
    "        - matching_scores0: confidence scores for matches\n",
    "    \"\"\"\n",
    "    \n",
    "    results = defaultdict(dict)\n",
    "    \n",
    "    def recursive_load(group, result_key):\n",
    "        \"\"\"\n",
    "        Recursively traverse H5 group and load data when keypoints are found.\n",
    "        \"\"\"\n",
    "        # Check if this group contains keypoints (leaf node)\n",
    "        if 'matches0' in group:\n",
    "            matches = np.array(group['matches0'][:], dtype=np.int32)\n",
    "            scores = np.array(group['matching_scores0'][:], dtype=np.float32)\n",
    "            \n",
    "            results[result_key]['matches0'] = matches\n",
    "            results[result_key]['matching_scores0'] = scores\n",
    "            return\n",
    "        \n",
    "        # If not leaf node, iterate through children\n",
    "        for key in group.keys():\n",
    "            item = group[key]\n",
    "            if isinstance(item, h5py.Group):\n",
    "                # Recurse into this group\n",
    "                recursive_load(item, f\"{result_key} {key}\" if result_key != \"\" else key)\n",
    "    \n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        recursive_load(f, result_key=\"\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c562dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_K(Ks, images, image):\n",
    "    sensor_id = images[image]['sensor_id']\n",
    "    return Ks[sensor_id]['K']\n",
    "\n",
    "def get_device_id(query_img, timestamp, query_device):\n",
    "    query_img = query_img.split(\"/\")\n",
    "    sub = query_img[0]\n",
    "    \n",
    "    if query_device == \"ios\":\n",
    "        query_device = f\"{sub}/cam_phone_{timestamp}\"\n",
    "    if query_device == \"hl\":\n",
    "        query_device = f\"{sub}/hetrig_{timestamp}\"\n",
    "    if query_device == \"spot\":\n",
    "        query_device = f\"{sub}/{timestamp}-body\"\n",
    "    \n",
    "    return query_device\n",
    "\n",
    "def estimate_poses(pairs, all_matches, all_kpts0, all_kpts1, query_images, map_images, query_Ks, map_Ks):\n",
    "    est_poses = {}\n",
    "    for query_img, map_img in pairs:\n",
    "        query_device = query_img.split(\"_\")[0]\n",
    "        \n",
    "        # Matches\n",
    "        matches, _ = all_matches[f\"{query_img.replace('/', '-')} {map_img.replace('/', '-')}\"].values()\n",
    "\n",
    "        # Keypoints\n",
    "        kpts0 = all_kpts0[query_img]['keypoints']\n",
    "        kpts1 = all_kpts1[map_img]['keypoints']\n",
    "            \n",
    "        # Keep the matching keypoints.\n",
    "        valid = matches > -1\n",
    "        mkpts0 = kpts0[valid]\n",
    "        mkpts1 = kpts1[matches[valid]]\n",
    "\n",
    "        # Estimate the pose and compute the pose error.\n",
    "        query_img = \"/\".join(query_img.split(\"/\")[2:])\n",
    "        map_img = \"/\".join(map_img.split(\"/\")[2:])\n",
    "        \n",
    "        K0 = get_K(query_Ks, query_images, query_img)\n",
    "        K1 = get_K(map_Ks, map_images, map_img)\n",
    "\n",
    "        thresh = 1.  # In pixels relative to resized image size.\n",
    "        est_pose = estimate_pose(mkpts0, mkpts1, K0, K1, thresh)\n",
    "        if est_pose is None: continue\n",
    "        \n",
    "        query_timestamp = query_images[query_img]['timestamp']\n",
    "        map_timestamp = map_images[map_img]['timestamp']\n",
    "        est_poses[f\"{query_timestamp}-{map_timestamp}\"] = {\n",
    "            \"pose\": est_pose,\n",
    "            \"device_id\": get_device_id(query_img, query_timestamp, query_device)\n",
    "        }\n",
    "    return est_poses\n",
    "\n",
    "def compute_errors(pairs, query_images, map_images, est_poses, query_poses, map_poses, query_rigs, map_rigs, top, Rt_threshold, r_margin):    \n",
    "    all_err_t, all_err_R = defaultdict(list), defaultdict(list)\n",
    "    good_pairs, bad_pairs = [], []\n",
    "    for query_img, map_img in pairs:\n",
    "        try:\n",
    "            query_img = \"/\".join(query_img.split(\"/\")[2:])\n",
    "            map_img = \"/\".join(map_img.split(\"/\")[2:])\n",
    "            query_timestamp, query_sensor = query_images[query_img]['timestamp'],  query_images[query_img]['sensor_id']\n",
    "            map_timestamp, map_sensor = map_images[map_img]['timestamp'],  map_images[map_img]['sensor_id']\n",
    "            \n",
    "            est_pose = est_poses[f\"{query_timestamp}-{map_timestamp}\"]['pose']\n",
    "            \n",
    "            query_pose = get_groundtruth(query_poses, query_rigs, query_timestamp, query_sensor)\n",
    "            map_pose = get_groundtruth(map_poses, map_rigs, map_timestamp, map_sensor)\n",
    "            \n",
    "            # TODD: T_0to1 is transform from query to map\n",
    "            T_0to1 = np.linalg.inv(map_pose) @ query_pose\n",
    "\n",
    "            err_t, err_R = compute_pose_error(T_0to1, est_pose)\n",
    "            \n",
    "            # Collect\n",
    "            all_err_t[query_img].append(err_t)\n",
    "            all_err_R[query_img].append(err_R)\n",
    "            \n",
    "            # Classify\n",
    "            if err_R < r_margin:\n",
    "                good_pairs.append((query_img, map_img, str(err_R)))\n",
    "            else:\n",
    "                bad_pairs.append((query_img, map_img, str(err_R)))\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    all_err_t = convert_to_list(all_err_t, top)\n",
    "    all_err_R = convert_to_list(all_err_R, top)\n",
    "    \n",
    "    th_r, th_t = Rt_threshold\n",
    "    recall = np.mean((all_err_R < th_r) & (all_err_t < th_t))\n",
    "    return all_err_t.mean(), all_err_R.mean(), recall, good_pairs, bad_pairs\n",
    "\n",
    "def get_q_t(pose):\n",
    "    Q, T, _ = pose\n",
    "    r = Rotation.from_matrix(Q)\n",
    "    q_xyzw = r.as_quat()\n",
    "    t = T\n",
    "    return q_xyzw, t\n",
    "\n",
    "def save_est_poses(file_path, est_poses):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        lines = \"\"\n",
    "        lines += \"# timestamp, device_id, qw, qx, qy, qz, tx, ty, tz, *covar\\n\"\n",
    "        for timestamp, data in est_poses.items():\n",
    "            line = [timestamp]\n",
    "            line.append(data['device_id'])\n",
    "            q_xyzw, t = get_q_t(data['pose'])\n",
    "            line.append(str(q_xyzw[3]))\n",
    "            line.append(str(q_xyzw[0]))\n",
    "            line.append(str(q_xyzw[1]))\n",
    "            line.append(str(q_xyzw[2]))\n",
    "            line.append(str(t[0]))\n",
    "            line.append(str(t[1]))\n",
    "            line.append(str(t[2]))\n",
    "            lines += \", \".join(line) + \"\\n\"\n",
    "        f.write(lines)\n",
    "    f.close()\n",
    "    print(f\"Saved estimated poses to {file_path}\")\n",
    "    \n",
    "def get_groundtruth(poses, rigs, timestamp, cam):\n",
    "    rig2world = poses[timestamp]['pose']\n",
    "    rig_id = poses[timestamp]['device_id']\n",
    "    \n",
    "    if \"rig_sensors\" in rigs.keys():\n",
    "        cam2rig = rigs[\"rig_sensors\"]['cam2rig']\n",
    "    else:\n",
    "        cam2rig = rigs[rig_id][cam]['cam2rig']\n",
    "    \n",
    "    return rig2world @ cam2rig\n",
    "\n",
    "def filter_top(results, n=5):\n",
    "    for k, v in results.items():\n",
    "        results[k] = sorted(v)[:n]\n",
    "    return results\n",
    "\n",
    "def convert_to_list(results, top=5):\n",
    "    results = filter_top(results, top)\n",
    "    result_list = []\n",
    "    for value_list in results.values():\n",
    "        result_list.extend(value_list)\n",
    "    return np.array(result_list)\n",
    "\n",
    "def save_pairs(pairs, save_dir, type):\n",
    "    save_path = f\"{save_dir}/{type}_pairs.txt\"\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        lines = \"# query_img, map_img, R_err\\n\"\n",
    "        for pair in pairs:\n",
    "            line = \", \".join(pair)\n",
    "            lines += line + '\\n'\n",
    "        f.write(lines)\n",
    "    print(f\"Saved {type} pairs to {save_path}\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16fbfa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pair(query_device, map_device, top, Rt_threshold, r_margin):\n",
    "    # Pairs\n",
    "    PAIRS_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/long/benchmarking_results/pair_selection/{query_device}_query/{map_device}_map/megaloc/pairs.txt\"\n",
    "    pairs = load_retrieval_pairs(PAIRS_PATH)\n",
    "\n",
    "    # Images\n",
    "    QUERY_IMAGES_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{query_device}_query/images.txt\"\n",
    "    MAP_IMAGES_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{map_device}_map/images.txt\"\n",
    "    query_images = load_images(QUERY_IMAGES_PATH)\n",
    "    map_images = load_images(MAP_IMAGES_PATH)\n",
    "    \n",
    "    SAVE_DIR = f\"estimate_pose/{query_device}_query/{map_device}_map\"\n",
    "    SAVE_PATH = f\"{SAVE_DIR}/est_poses.txt\"\n",
    "    \n",
    "    if not os.path.exists(SAVE_PATH):\n",
    "        # Keypoints\n",
    "        KPTS0_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/long/benchmarking_results/extraction/{query_device}_query/superpoint/features.h5\"\n",
    "        all_kpts0 = load_keypoints(KPTS0_PATH)\n",
    "        KPTS1_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/long/benchmarking_results/extraction/{map_device}_map/superpoint/features.h5\"\n",
    "        all_kpts1 = load_keypoints(KPTS1_PATH)\n",
    "\n",
    "        # Matches\n",
    "        MATCHES_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/long/benchmarking_results/matching/{query_device}_query/{map_device}_map/superpoint/lightglue/matches.h5\"\n",
    "        all_matches = load_matches(MATCHES_PATH)\n",
    "\n",
    "        # Intrinsics\n",
    "        QUERY_SENSORS_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{query_device}_query/sensors.txt\"\n",
    "        MAP_SENSORS_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{map_device}_map/sensors.txt\"\n",
    "        query_Ks = load_intrinsics(QUERY_SENSORS_PATH)\n",
    "        map_Ks = load_intrinsics(MAP_SENSORS_PATH)\n",
    "        \n",
    "        est_poses = estimate_poses(pairs, all_matches, all_kpts0, all_kpts1, query_images, map_images, query_Ks, map_Ks)\n",
    "        save_est_poses(SAVE_PATH, est_poses)\n",
    "    else:\n",
    "        est_poses = load_poses(SAVE_PATH)\n",
    "        \n",
    "    # Poses\n",
    "    QUERY_POSES_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{query_device}_query/proc/alignment_trajectories.txt\"\n",
    "    MAP_POSES_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{map_device}_map/trajectories.txt\"\n",
    "    query_poses = load_poses(QUERY_POSES_PATH)\n",
    "    map_poses = load_poses(MAP_POSES_PATH)\n",
    "\n",
    "    # Rigs\n",
    "    QUERY_RIGS_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{query_device}_query/rigs.txt\" if query_device != \"ios\" else None\n",
    "    MAP_RIGS_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{map_device}_map/rigs.txt\" if map_device != \"ios\" else None\n",
    "    query_rigs = load_rigs(QUERY_RIGS_PATH)\n",
    "    map_rigs = load_rigs(MAP_RIGS_PATH)\n",
    "        \n",
    "    all_err_t, all_err_R, recall, good_pairs, bad_pairs = compute_errors(pairs, query_images, map_images, est_poses, query_poses, map_poses, query_rigs, map_rigs, top, Rt_threshold, r_margin)\n",
    "    save_pairs(good_pairs, SAVE_DIR, 'good')\n",
    "    save_pairs(bad_pairs, SAVE_DIR, 'bad')\n",
    "    gc.collect()\n",
    "    \n",
    "    return all_err_t, all_err_R, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3ab1abfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** ios-ios (top 5) **********\n",
      "Saved good pairs to estimate_pose/ios_query/ios_map/good_pairs.txt\n",
      "Saved bad pairs to estimate_pose/ios_query/ios_map/bad_pairs.txt\n",
      "4.78 || 4.85 || 0.93\n",
      "********** ios-hl (top 5) **********\n",
      "Saved good pairs to estimate_pose/ios_query/hl_map/good_pairs.txt\n",
      "Saved bad pairs to estimate_pose/ios_query/hl_map/bad_pairs.txt\n",
      "15.93 || 20.09 || 0.68\n",
      "********** ios-spot (top 5) **********\n",
      "Saved good pairs to estimate_pose/ios_query/spot_map/good_pairs.txt\n",
      "Saved bad pairs to estimate_pose/ios_query/spot_map/bad_pairs.txt\n",
      "27.57 || 36.57 || 0.46\n",
      "********** hl-ios (top 5) **********\n",
      "Saved good pairs to estimate_pose/hl_query/ios_map/good_pairs.txt\n",
      "Saved bad pairs to estimate_pose/hl_query/ios_map/bad_pairs.txt\n",
      "8.59 || 10.39 || 0.83\n",
      "********** hl-hl (top 5) **********\n",
      "Saved good pairs to estimate_pose/hl_query/hl_map/good_pairs.txt\n",
      "Saved bad pairs to estimate_pose/hl_query/hl_map/bad_pairs.txt\n",
      "8.70 || 3.25 || 0.86\n",
      "********** hl-spot (top 5) **********\n",
      "Saved good pairs to estimate_pose/hl_query/spot_map/good_pairs.txt\n",
      "Saved bad pairs to estimate_pose/hl_query/spot_map/bad_pairs.txt\n",
      "22.59 || 26.27 || 0.54\n",
      "********** spot-ios (top 5) **********\n",
      "Saved good pairs to estimate_pose/spot_query/ios_map/good_pairs.txt\n",
      "Saved bad pairs to estimate_pose/spot_query/ios_map/bad_pairs.txt\n",
      "18.87 || 27.38 || 0.53\n",
      "********** spot-hl (top 5) **********\n",
      "Saved good pairs to estimate_pose/spot_query/hl_map/good_pairs.txt\n",
      "Saved bad pairs to estimate_pose/spot_query/hl_map/bad_pairs.txt\n",
      "24.39 || 35.45 || 0.42\n",
      "********** spot-spot (top 5) **********\n",
      "Saved good pairs to estimate_pose/spot_query/spot_map/good_pairs.txt\n",
      "Saved bad pairs to estimate_pose/spot_query/spot_map/bad_pairs.txt\n",
      "13.66 || 3.53 || 0.76\n"
     ]
    }
   ],
   "source": [
    "QUERY_DEVICES = [\"ios\", \"hl\", \"spot\"]\n",
    "MAP_DEVICES = [\"ios\", \"hl\", \"spot\"]\n",
    "\n",
    "top = 5\n",
    "Rt_threshold = (20.0, 20.0)\n",
    "r_margin = 5.0\n",
    "\n",
    "results = defaultdict(dict)\n",
    "for query_device in QUERY_DEVICES:\n",
    "    for map_device in MAP_DEVICES:\n",
    "        print(f\"{'*'*10} {query_device}-{map_device} (top {top}) {'*'*10}\")\n",
    "        err_t, err_R, recall = evaluate_pair(query_device, map_device, top, Rt_threshold, r_margin)\n",
    "        results[query_device][map_device] = {\n",
    "            \"err_t\": err_t,\n",
    "            \"err_R\": err_R, \n",
    "            \"recall\": recall\n",
    "        }\n",
    "        print(f\"{err_t:.2f} || {err_R:.2f} || {recall:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f65e60bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>,\n",
      "            {'hl': {'hl': {'err_R': 3.2541068861789033,\n",
      "                           'err_t': 8.701040292548322,\n",
      "                           'recall': 0.8603712671509282},\n",
      "                    'ios': {'err_R': 10.387546828152527,\n",
      "                            'err_t': 8.585823968380561,\n",
      "                            'recall': 0.8258746948738812},\n",
      "                    'spot': {'err_R': 26.268981845563747,\n",
      "                             'err_t': 22.59320267734755,\n",
      "                             'recall': 0.5378356387306753}},\n",
      "             'ios': {'hl': {'err_R': 20.09436891100037,\n",
      "                            'err_t': 15.925424598319045,\n",
      "                            'recall': 0.6817359855334539},\n",
      "                     'ios': {'err_R': 4.854526889174639,\n",
      "                             'err_t': 4.779456928839683,\n",
      "                             'recall': 0.9344552701505757},\n",
      "                     'spot': {'err_R': 36.57144754878939,\n",
      "                              'err_t': 27.567702270363366,\n",
      "                              'recall': 0.45891043397968606}},\n",
      "             'spot': {'hl': {'err_R': 35.45452502712742,\n",
      "                             'err_t': 24.386704970701206,\n",
      "                             'recall': 0.42358242583552386},\n",
      "                      'ios': {'err_R': 27.384957634742005,\n",
      "                              'err_t': 18.872031363211203,\n",
      "                              'recall': 0.5339542103220799},\n",
      "                      'spot': {'err_R': 3.5309730909025907,\n",
      "                               'err_t': 13.66479984636137,\n",
      "                               'recall': 0.7628903413217138}}})\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd0fced8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ios         hl       spot \n",
      "   ios     4.8545    20.0944    36.5714 \n",
      "    hl    10.3875     3.2541    26.2690 \n",
      "  spot    27.3850    35.4545     3.5310 \n"
     ]
    }
   ],
   "source": [
    "def show_matrix(results, metric):\n",
    "    # Get all labels\n",
    "    labels = list(results.keys())\n",
    "\n",
    "    # Print header\n",
    "    print(f\"{'':>6}\", end=' ')\n",
    "    for col in labels:\n",
    "        print(f\"{col:>10}\", end=' ')\n",
    "    print()\n",
    "\n",
    "    # Print rows\n",
    "    for row in labels:\n",
    "        print(f\"{row:>6}\", end=' ')\n",
    "        for col in labels:\n",
    "            value = results[row][col][metric]\n",
    "            print(f\"{value:10.4f}\", end=' ')\n",
    "        print()\n",
    "\n",
    "metric = 'err_R' # err_R, err_t, acc_R, recall\n",
    "show_matrix(results, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0e0b6e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Python dependencies...\n",
      "Dependencies OK\n",
      "You are running with parameters: \n",
      "  Capture: ./capture\n",
      "  Output: ./capture/evaluation_results\n",
      "  Benchmarking dir: long/benchmarking_results\n",
      "  Local feature method: superpoint\n",
      "  Matching method: lightglue\n",
      "  Global feature method: megaloc\n",
      "  Scenes: arche_d2\n",
      "  Devices map: ios hl spot\n",
      "  Devices query: ios hl spot\n",
      "  Position threshold: 0.5 meters\n",
      "  Rotation threshold: 5 degrees\n",
      "Running evaluation...\n",
      "Starting cross-device pose estimation evaluation\n",
      "Configuration:\n",
      "  Capture dir: ./capture\n",
      "  Benchmarking dir: long/benchmarking_results\n",
      "  Local feature method: superpoint\n",
      "  Matching method: lightglue\n",
      "  Global feature method: megaloc\n",
      "  Scenes: ['arche_d2']\n",
      "  Map devices: ['ios', 'hl', 'spot']\n",
      "  Query devices: ['ios', 'hl', 'spot']\n",
      "  Position threshold: 0.5\n",
      "  Rotation threshold: 5.0\n",
      "\n",
      "Processing scene: arche_d2\n",
      "Evaluating arche_d2: ios query vs ios map\n",
      "Evaluating arche_d2: ios query vs hl map\n",
      "Evaluating arche_d2: ios query vs spot map\n",
      "Evaluating arche_d2: hl query vs ios map\n",
      "Evaluating arche_d2: hl query vs hl map\n",
      "Evaluating arche_d2: hl query vs spot map\n",
      "Evaluating arche_d2: spot query vs ios map\n",
      "Evaluating arche_d2: spot query vs hl map\n",
      "Evaluating arche_d2: spot query vs spot map\n",
      "\n",
      "Computing overall success rate matrix\n",
      "\n",
      "ARCHE_D2 Success Rate Matrix\n",
      "----------------------------\n",
      "Query\\Map   IOS         HL          SPOT        \n",
      "------------------------------------------------\n",
      "IOS            95.58%      83.63%      56.89%   \n",
      "HL             98.86%     100.00%      84.09%   \n",
      "SPOT          100.00%      96.38%     100.00%   \n",
      "\n",
      "OVERALL Success Rate Matrix\n",
      "---------------------------\n",
      "Query\\Map   IOS         HL          SPOT        \n",
      "------------------------------------------------\n",
      "IOS            95.58%      83.63%      56.89%   \n",
      "HL             98.86%     100.00%      84.09%   \n",
      "SPOT          100.00%      96.38%     100.00%   \n",
      "\n",
      "Results saved to ./capture/evaluation_results/long/benchmarking_results\n",
      "\n",
      "Evaluation completed successfully!\n",
      "\n",
      "Evaluation completed!\n",
      "Results saved to: ./capture/evaluation_results\n"
     ]
    }
   ],
   "source": [
    "!cd ~/Workspace/crocodl-benchmark && export CAPTURE_DIR=./capture && bash ./evaluate/evaluate.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21218bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "92290294",
   "metadata": {},
   "outputs": [],
   "source": [
    "EST_POSES_COLOR = [255, 0, 0]\n",
    "TRAJ_COLOR = [0, 255, 0]\n",
    "ALM_TRAJ_COLOR = [0, 0, 255]\n",
    "\n",
    "def visualize_poses(query_device, map_device):\n",
    "    import sys\n",
    "    import os\n",
    "\n",
    "    # Add project root to path\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "    if project_root not in sys.path:\n",
    "        sys.path.insert(0, project_root)\n",
    "        \n",
    "    from visualize.cam_pose_visualizer import CamPoseVisualizer, load_gt_and_est_poses\n",
    "\n",
    "    visualizer = CamPoseVisualizer()\n",
    "    \n",
    "    est_poses_path = f\"estimate_pose/{query_device}_query/{map_device}_map/est_poses.txt\"\n",
    "    traj_path = f'/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{query_device}_query/trajectories.txt'\n",
    "    alm_traj_path = f'/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{query_device}_query/proc/alignment_trajectories.txt'\n",
    "    sensors_path = f'/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{query_device}_query/sensors.txt'\n",
    "    rigs_path = None if query_device == 'ios' else f'/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{query_device}_query/rigs.txt'\n",
    "    est_poses, traj = load_gt_and_est_poses(est_poses_path, traj_path, sensors_path, rigs_path, EST_POSES_COLOR, TRAJ_COLOR)\n",
    "    est_poses, alm_traj = load_gt_and_est_poses(est_poses_path, alm_traj_path, sensors_path, rigs_path, EST_POSES_COLOR, ALM_TRAJ_COLOR)\n",
    "    \n",
    "    visualizer.visualize(est_poses + traj + alm_traj)\n",
    "    \n",
    "# visualize_poses(query_device, map_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "19da33f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc': [9, 8, 7, 6, 5]}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def filter_top(results: dict, n: int = 5):\n",
    "    for k, v in results.items():\n",
    "        results[k] = sorted(v, reverse=True)[:n]\n",
    "    return results\n",
    "\n",
    "def get_error(results: dict, top: int = 5):\n",
    "    results = filter_top(top)\n",
    "    result_list = []\n",
    "    for value_list in results.values():\n",
    "        result_list.extend(value_list)\n",
    "    return np.mean(np.array(result_list))\n",
    "\n",
    "results = {\n",
    "    \"abc\": np.arange(10, dtype=int)\n",
    "}\n",
    "\n",
    "filter_top(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2794c5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "my_dict = {'key1': [1, 2, 3], 'key2': [4, 5], 'key3': [6, 7, 8, 9]}\n",
    "result_list = []\n",
    "for value_list in my_dict.values():\n",
    "    result_list.extend(value_list)\n",
    "print(result_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "croco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
