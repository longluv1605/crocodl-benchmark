{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b4d8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import h5py\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe5ef685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pose(kpts0, kpts1, K0, K1, thresh, conf=0.99999):\n",
    "    if len(kpts0) < 5:\n",
    "        return None\n",
    "\n",
    "    f_mean = np.mean([K0[0, 0], K1[1, 1], K0[0, 0], K1[1, 1]])\n",
    "    norm_thresh = thresh / f_mean\n",
    "\n",
    "    kpts0 = (kpts0 - K0[[0, 1], [2, 2]][None]) / K0[[0, 1], [0, 1]][None]\n",
    "    kpts1 = (kpts1 - K1[[0, 1], [2, 2]][None]) / K1[[0, 1], [0, 1]][None]\n",
    "\n",
    "    E, mask = cv2.findEssentialMat(\n",
    "        kpts0, kpts1, np.eye(3), threshold=norm_thresh, prob=conf,\n",
    "        method=cv2.RANSAC)\n",
    "\n",
    "    if E is None:\n",
    "        return None\n",
    "\n",
    "    best_num_inliers = 0\n",
    "    ret = None\n",
    "    for _E in np.split(E, len(E) / 3):\n",
    "        n, R, t, _ = cv2.recoverPose(\n",
    "            _E, kpts0, kpts1, np.eye(3), 1e9, mask=mask)\n",
    "        if n > best_num_inliers:\n",
    "            best_num_inliers = n\n",
    "            ret = (R, t[:, 0], mask.ravel() > 0)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def angle_error_mat(R1, R2):\n",
    "    cos = (np.trace(np.dot(R1.T, R2)) - 1) / 2\n",
    "    cos = np.clip(cos, -1., 1.)  # numercial errors can make it out of bounds\n",
    "    return np.rad2deg(np.abs(np.arccos(cos)))\n",
    "\n",
    "\n",
    "def angle_error_vec(v1, v2):\n",
    "    n = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "    return np.rad2deg(np.arccos(np.clip(np.dot(v1, v2) / n, -1.0, 1.0)))\n",
    "\n",
    "\n",
    "def compute_pose_error(T_0to1, R, t):\n",
    "    R_gt = T_0to1[:3, :3]\n",
    "    t_gt = T_0to1[:3, 3]\n",
    "    error_t = angle_error_vec(t, t_gt)\n",
    "    error_t = np.minimum(error_t, 180 - error_t)  # ambiguity of E estimation\n",
    "    error_R = angle_error_mat(R, R_gt)\n",
    "    return error_t, error_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc340d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_retrieval_pairs(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        pairs = []\n",
    "        for line in f:\n",
    "            pair = line.strip().split(\" \")\n",
    "            pairs.append(pair)\n",
    "    f.close()\n",
    "    return pairs\n",
    "\n",
    "def load_images(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        images = defaultdict(dict)\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"): continue\n",
    "            timestamp, sensor_id, image_path = line.strip().split(\", \")\n",
    "            images[image_path] = {\n",
    "                \"timestamp\": timestamp,\n",
    "                \"sensor_id\": sensor_id\n",
    "            }\n",
    "    return images\n",
    "\n",
    "def load_intrinsics(file_path):\n",
    "    sensors = defaultdict(dict)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"): continue\n",
    "            line = line.strip().split(\", \")\n",
    "            if len(line) < 6: continue\n",
    "            \n",
    "            sensor_id = line[0]\n",
    "            width, height = line[4:6]\n",
    "            fx, fy, cx, cy = line[6:]\n",
    "            K = np.array([\n",
    "                [fx, 0, cx],\n",
    "                [0, fy, cy],\n",
    "                [0, 0, 1],\n",
    "            ], dtype=float)\n",
    "            \n",
    "            sensors[sensor_id] = {\n",
    "                'K': K,\n",
    "                'width': int(width),\n",
    "                'height': int(height),\n",
    "            }\n",
    "    return sensors\n",
    "\n",
    "def load_rigs(file_path):\n",
    "    if file_path is None:\n",
    "        q = {'x': 0.0, 'y': 0.0, 'z': 0.0, 'w': 1.0}    # No rotate\n",
    "        t = {'x': 0.0, 'y': 0.0, 'z': 0.0}              # No translate\n",
    "        q_xyzw = np.array([q['x'], q['y'], q['z'], q['w']])\n",
    "        Q = Rotation.from_quat(q_xyzw).as_matrix()\n",
    "        T = np.array([t['x'], t['y'], t['z']])\n",
    "        \n",
    "        cam2rig = np.eye(4)\n",
    "        cam2rig[:3, :3] = Q\n",
    "        cam2rig[:3, 3] = T\n",
    "        \n",
    "        return {\n",
    "            'rig_sensors': {\n",
    "                'cam2rig': cam2rig,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    rigs = defaultdict(dict)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"): continue\n",
    "            line = line.strip().split(\", \")\n",
    "            \n",
    "            # rig_id = line[0].split(\"_\")[-1]\n",
    "            # sensor_id = line[1].split(\"/\")[-1]\n",
    "            \n",
    "            rig_id = line[0]\n",
    "            sensor_id = line[1]\n",
    "            q = {\n",
    "                'w': float(line[2]),\n",
    "                'x': float(line[3]),\n",
    "                'y': float(line[4]),\n",
    "                'z': float(line[5]),\n",
    "            }\n",
    "            t = {\n",
    "                'x': float(line[6]),\n",
    "                'y': float(line[7]),\n",
    "                'z': float(line[8]),\n",
    "            }\n",
    "            \n",
    "            q_xyzw = np.array([q['x'], q['y'], q['z'], q['w']])\n",
    "            Q = Rotation.from_quat(q_xyzw).as_matrix()\n",
    "            T = np.array([t['x'], t['y'], t['z']])\n",
    "            \n",
    "            cam2rig = np.eye(4)\n",
    "            cam2rig[:3, :3] = Q\n",
    "            cam2rig[:3, 3] = T\n",
    "            \n",
    "            rigs[rig_id][sensor_id] = {\n",
    "                'cam2rig': cam2rig,\n",
    "            }\n",
    "    return rigs\n",
    "\n",
    "def load_poses(file_path):\n",
    "    poses = defaultdict(dict)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"): continue\n",
    "            line = line.strip().split(\", \")\n",
    "            timestamp = line[0]\n",
    "            device_id = line[1]\n",
    "            \n",
    "            q = {\n",
    "                'w': float(line[2]),\n",
    "                'x': float(line[3]),\n",
    "                'y': float(line[4]),\n",
    "                'z': float(line[5]),\n",
    "            }\n",
    "            t = {\n",
    "                'x': float(line[6]),\n",
    "                'y': float(line[7]),\n",
    "                'z': float(line[8]),\n",
    "            }\n",
    "            \n",
    "            q_xyzw = np.array([q['x'], q['y'], q['z'], q['w']])\n",
    "            Q = Rotation.from_quat(q_xyzw).as_matrix()\n",
    "            T = np.array([t['x'], t['y'], t['z']])\n",
    "            pose = np.eye(4)\n",
    "            pose[:3, :3] = Q\n",
    "            pose[:3, 3] = T\n",
    "            poses[timestamp] = {\n",
    "                'pose': pose,\n",
    "                'device_id': device_id\n",
    "            }\n",
    "    return poses\n",
    "\n",
    "def load_keypoints(file_path):\n",
    "    \"\"\"\n",
    "    Load keypoints and descriptors from H5 file.\n",
    "    \n",
    "    Supports two structures:\n",
    "    \n",
    "    Structure 1 (ios_query):\n",
    "    - {session}/raw_data/{subsession}/images/{image_id}/\n",
    "      - keypoints, descriptors, scores, image_size\n",
    "    \n",
    "    Structure 2 (spot_query):\n",
    "    - {session}/raw_data/{subsession}/{camera}/{image_id}/\n",
    "      - keypoints, descriptors, scores, image_size\n",
    "    \n",
    "    Structure 3 (hl_query):\n",
    "    - {session}/raw_data/{subsession}/images/{camera}/{image_id}/\n",
    "      - keypoints, descriptors, scores, image_size\n",
    "    \n",
    "    Returns nested dicts with flexible structure based on hierarchy depth.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = defaultdict(dict)\n",
    "    \n",
    "    def recursive_load(group, result_key):\n",
    "        \"\"\"\n",
    "        Recursively traverse H5 group and load data when keypoints are found.\n",
    "        \"\"\"\n",
    "        # Check if this group contains keypoints (leaf node)\n",
    "        if 'keypoints' in group:\n",
    "            keypoints = np.array(group['keypoints'][:], dtype=np.int32)\n",
    "            descriptors = np.array(group['descriptors'][:], dtype=np.float32)\n",
    "            scores = np.array(group['scores'][:], dtype=np.float32)\n",
    "            image_size = np.array(group['image_size'][:], dtype=np.int32)\n",
    "            \n",
    "            results[result_key]['keypoints'] = keypoints\n",
    "            results[result_key]['descriptors'] = descriptors\n",
    "            results[result_key]['scores'] = scores\n",
    "            results[result_key]['image_size'] = image_size\n",
    "            return\n",
    "        \n",
    "        # If not leaf node, iterate through children\n",
    "        for key in group.keys():\n",
    "            item = group[key]\n",
    "            if isinstance(item, h5py.Group):\n",
    "                # Recurse into this group\n",
    "                recursive_load(item, f\"{result_key}{'/' if result_key != '' else ''}{key}\")\n",
    "    \n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        recursive_load(f, result_key=\"\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def load_matches(file_path):\n",
    "    \"\"\"\n",
    "    Load matching results from H5 file.\n",
    "    \n",
    "    Structure:\n",
    "    - Group for each query image\n",
    "      - Group for each map image\n",
    "        - matches0: matched indices in map image (-1 means no match)\n",
    "        - matching_scores0: confidence scores for matches\n",
    "    \"\"\"\n",
    "    \n",
    "    results = defaultdict(dict)\n",
    "    \n",
    "    def recursive_load(group, result_key):\n",
    "        \"\"\"\n",
    "        Recursively traverse H5 group and load data when keypoints are found.\n",
    "        \"\"\"\n",
    "        # Check if this group contains keypoints (leaf node)\n",
    "        if 'matches0' in group:\n",
    "            matches = np.array(group['matches0'][:], dtype=np.int32)\n",
    "            scores = np.array(group['matching_scores0'][:], dtype=np.float32)\n",
    "            \n",
    "            results[result_key]['matches0'] = matches\n",
    "            results[result_key]['matching_scores0'] = scores\n",
    "            return\n",
    "        \n",
    "        # If not leaf node, iterate through children\n",
    "        for key in group.keys():\n",
    "            item = group[key]\n",
    "            if isinstance(item, h5py.Group):\n",
    "                # Recurse into this group\n",
    "                recursive_load(item, f\"{result_key} {key}\" if result_key != \"\" else key)\n",
    "    \n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        recursive_load(f, result_key=\"\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c562dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_K(Ks, images, image):\n",
    "    sensor_id = images[image]['sensor_id']\n",
    "    return Ks[sensor_id]['K']\n",
    "\n",
    "def get_device_id(query_img, timestamp, query_device):\n",
    "    query_img = query_img.split(\"/\")\n",
    "    sub = query_img[0]\n",
    "    \n",
    "    if query_device == \"ios\":\n",
    "        query_device = f\"{sub}/cam_phone_{timestamp}\"\n",
    "    if query_device == \"hl\":\n",
    "        query_device = f\"{sub}/hetrig_{timestamp}\"\n",
    "    if query_device == \"spot\":\n",
    "        query_device = f\"{sub}/{timestamp}-body\"\n",
    "    \n",
    "    return query_device\n",
    "\n",
    "def estimate_poses(pairs, all_matches, all_kpts0, all_kpts1, query_images, map_images, query_Ks, map_Ks):\n",
    "    est_poses = {}\n",
    "    for query_img, map_img in pairs:\n",
    "        query_device = query_img.split(\"_\")[0]\n",
    "        \n",
    "        # Matches\n",
    "        matches, _ = all_matches[f\"{query_img.replace('/', '-')} {map_img.replace('/', '-')}\"].values()\n",
    "\n",
    "        # Keypoints\n",
    "        kpts0 = all_kpts0[query_img]['keypoints']\n",
    "        kpts1 = all_kpts1[map_img]['keypoints']\n",
    "            \n",
    "        # Keep the matching keypoints.\n",
    "        valid = matches > -1\n",
    "        mkpts0 = kpts0[valid]\n",
    "        mkpts1 = kpts1[matches[valid]]\n",
    "\n",
    "        # Estimate the pose and compute the pose error.\n",
    "        query_img = \"/\".join(query_img.split(\"/\")[2:])\n",
    "        map_img = \"/\".join(map_img.split(\"/\")[2:])\n",
    "        \n",
    "        K0 = get_K(query_Ks, query_images, query_img)\n",
    "        K1 = get_K(map_Ks, map_images, map_img)\n",
    "\n",
    "        thresh = 1.  # In pixels relative to resized image size.\n",
    "        est_pose = estimate_pose(mkpts0, mkpts1, K0, K1, thresh)\n",
    "        if est_pose is None: continue\n",
    "        \n",
    "        query_timestamp = query_images[query_img]['timestamp']\n",
    "        map_timestamp = map_images[map_img]['timestamp']\n",
    "        est_poses[f\"{query_timestamp}-{map_timestamp}\"] = {\n",
    "            \"pose\": est_pose,\n",
    "            \"device_id\": get_device_id(query_img, query_timestamp, query_device)\n",
    "        }\n",
    "    return est_poses\n",
    "\n",
    "def get_q_t(pose):\n",
    "    Q, T, _ = pose\n",
    "    r = Rotation.from_matrix(Q)\n",
    "    q_xyzw = r.as_quat()\n",
    "    t = T\n",
    "    return q_xyzw, t\n",
    "\n",
    "def save_est_poses(file_path, est_poses):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        lines = \"\"\n",
    "        lines += \"# timestamp, device_id, qw, qx, qy, qz, tx, ty, tz, *covar\\n\"\n",
    "        for timestamp, data in est_poses.items():\n",
    "            line = [timestamp]\n",
    "            line.append(data['device_id'])\n",
    "            q_xyzw, t = get_q_t(data['pose'])\n",
    "            line.append(str(q_xyzw[3]))\n",
    "            line.append(str(q_xyzw[0]))\n",
    "            line.append(str(q_xyzw[1]))\n",
    "            line.append(str(q_xyzw[2]))\n",
    "            line.append(str(t[0]))\n",
    "            line.append(str(t[1]))\n",
    "            line.append(str(t[2]))\n",
    "            lines += \", \".join(line) + \"\\n\"\n",
    "        f.write(lines)\n",
    "    f.close()\n",
    "    print(f\"Saved estimated poses to {file_path}\")\n",
    "    \n",
    "def get_groundtruth(poses, rigs, timestamp, cam):\n",
    "    rig2world = poses[timestamp]['pose']\n",
    "    rig_id = poses[timestamp]['device_id']\n",
    "    \n",
    "    if \"rig_sensors\" in rigs.keys():\n",
    "        cam2rig = rigs[\"rig_sensors\"]['cam2rig']\n",
    "    else:\n",
    "        cam2rig = rigs[rig_id][cam]['cam2rig']\n",
    "    \n",
    "    return rig2world @ cam2rig\n",
    "\n",
    "def compute_errors(pairs, query_images, map_images, est_poses, query_poses, map_poses, query_rigs, map_rigs, Rt_threshold):\n",
    "    all_err_t, all_err_R = [], []\n",
    "    for query_img, map_img in pairs:\n",
    "        try:\n",
    "            query_img = \"/\".join(query_img.split(\"/\")[2:])\n",
    "            map_img = \"/\".join(map_img.split(\"/\")[2:])\n",
    "            query_timestamp, query_sensor = query_images[query_img]['timestamp'],  query_images[query_img]['sensor_id']\n",
    "            map_timestamp, map_sensor = map_images[map_img]['timestamp'],  map_images[map_img]['sensor_id']\n",
    "            \n",
    "            est_pose = est_poses[f\"{query_timestamp}-{map_timestamp}\"]['pose']\n",
    "            R, t, inliers = est_pose\n",
    "            \n",
    "            query_pose = get_groundtruth(query_poses, query_rigs, query_timestamp, query_sensor)\n",
    "            map_pose = get_groundtruth(map_poses, map_rigs, map_timestamp, map_sensor)\n",
    "            \n",
    "            # TODD: T_0to1 is transform from query to map\n",
    "            T_0to1 = np.linalg.inv(map_pose) @ query_pose\n",
    "\n",
    "            err_t, err_R = compute_pose_error(T_0to1, R, t)\n",
    "            all_err_t.append(err_t)\n",
    "            all_err_R.append(err_R)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    all_err_t = np.array(all_err_t)\n",
    "    all_err_R = np.array(all_err_R)\n",
    "    \n",
    "    th_r, th_t = Rt_threshold\n",
    "    recall = np.mean((all_err_R < th_r) & (all_err_t < th_t))\n",
    "    return all_err_t.mean(), all_err_R.mean(), recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "158717b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' TODO\\nSố lượng pairs sẽ bằng 10 lần số query do lấy top 10 trong retrieval.\\nVà mỗi pair sẽ tính pose 1 lần nên phải có 10x pairs.\\nTuy nhiên hiện chỉ có x, vì lưu dạng dict nên timestamp chỉ có duy nhất nên sẽ chỉ lưu lại lần tính cuối cùng của ID đó.\\nCần phải xử lý chỗ này.\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" TODO\n",
    "Số lượng pairs sẽ bằng 10 lần số query do lấy top 10 trong retrieval.\n",
    "Và mỗi pair sẽ tính pose 1 lần nên phải có 10x pairs.\n",
    "Tuy nhiên hiện chỉ có x, vì lưu dạng dict nên timestamp chỉ có duy nhất nên sẽ chỉ lưu lại lần tính cuối cùng của ID đó.\n",
    "Cần phải xử lý chỗ này.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16fbfa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pair(query_device, map_device, Rt_threshold):\n",
    "    # Pairs\n",
    "    PAIRS_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/long/benchmarking_results/pair_selection/{query_device}_query/{map_device}_map/megaloc/pairs.txt\"\n",
    "    pairs = load_retrieval_pairs(PAIRS_PATH)\n",
    "\n",
    "    # Images\n",
    "    QUERY_IMAGES_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{query_device}_query/images.txt\"\n",
    "    MAP_IMAGES_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{map_device}_map/images.txt\"\n",
    "    query_images = load_images(QUERY_IMAGES_PATH)\n",
    "    map_images = load_images(MAP_IMAGES_PATH)\n",
    "    \n",
    "    SAVE_PATH = f\"estimate_pose/{query_device}_query/{map_device}_map/est_poses.txt\"\n",
    "    \n",
    "    if not os.path.exists(SAVE_PATH):\n",
    "        # Keypoints\n",
    "        KPTS0_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/long/benchmarking_results/extraction/{query_device}_query/superpoint/features.h5\"\n",
    "        all_kpts0 = load_keypoints(KPTS0_PATH)\n",
    "        KPTS1_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/long/benchmarking_results/extraction/{map_device}_map/superpoint/features.h5\"\n",
    "        all_kpts1 = load_keypoints(KPTS1_PATH)\n",
    "\n",
    "        # Matches\n",
    "        MATCHES_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/long/benchmarking_results/matching/{query_device}_query/{map_device}_map/superpoint/lightglue/matches.h5\"\n",
    "        all_matches = load_matches(MATCHES_PATH)\n",
    "\n",
    "        # Intrinsics\n",
    "        QUERY_SENSORS_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{query_device}_query/sensors.txt\"\n",
    "        MAP_SENSORS_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{map_device}_map/sensors.txt\"\n",
    "        query_Ks = load_intrinsics(QUERY_SENSORS_PATH)\n",
    "        map_Ks = load_intrinsics(MAP_SENSORS_PATH)\n",
    "        \n",
    "        est_poses = estimate_poses(pairs, all_matches, all_kpts0, all_kpts1, query_images, map_images, query_Ks, map_Ks)\n",
    "        save_est_poses(SAVE_PATH, est_poses)\n",
    "    else:\n",
    "        est_poses = load_poses(SAVE_PATH)\n",
    "        \n",
    "    # Poses\n",
    "    QUERY_POSES_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{query_device}_query/proc/alignment_trajectories.txt\"\n",
    "    MAP_POSES_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{map_device}_map/trajectories.txt\"\n",
    "    query_poses = load_poses(QUERY_POSES_PATH)\n",
    "    map_poses = load_poses(MAP_POSES_PATH)\n",
    "\n",
    "    # Rigs\n",
    "    QUERY_RIGS_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{query_device}_query/rigs.txt\" if query_device != \"ios\" else None\n",
    "    MAP_RIGS_PATH = f\"/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{map_device}_map/rigs.txt\" if map_device != \"ios\" else None\n",
    "    query_rigs = load_rigs(QUERY_RIGS_PATH)\n",
    "    map_rigs = load_rigs(MAP_RIGS_PATH)\n",
    "        \n",
    "    all_err_t, all_err_R, recall = compute_errors(pairs, query_images, map_images, est_poses, query_poses, map_poses, query_rigs, map_rigs, Rt_threshold)\n",
    "    gc.collect()\n",
    "    \n",
    "    return all_err_t, all_err_R, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ab1abfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ios-ios == nan || nan || nan\n",
      "ios-hl == nan || nan || nan\n",
      "ios-spot == "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_183373/1522823729.py:122: RuntimeWarning: Mean of empty slice.\n",
      "  return all_err_t.mean(), all_err_R.mean(), recall\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan || nan || nan\n",
      "hl-ios == nan || nan || nan\n",
      "hl-hl == nan || nan || nan\n",
      "hl-spot == nan || nan || nan\n",
      "spot-ios == nan || nan || nan\n",
      "spot-hl == nan || nan || nan\n",
      "spot-spot == nan || nan || nan\n"
     ]
    }
   ],
   "source": [
    "QUERY_DEVICES = [\"ios\", \"hl\", \"spot\"]\n",
    "MAP_DEVICES = [\"ios\", \"hl\", \"spot\"]\n",
    "Rt_threshold = (20.0, 50.0)\n",
    "\n",
    "results = defaultdict(dict)\n",
    "for query_device in QUERY_DEVICES:\n",
    "    for map_device in MAP_DEVICES:\n",
    "        print(f\"{query_device}-{map_device} ==\", end=\" \")\n",
    "        err_t, err_R, recall = evaluate_pair(query_device, map_device, Rt_threshold)\n",
    "        results[query_device][map_device] = {\n",
    "            \"err_t\": err_t,\n",
    "            \"err_R\": err_R, \n",
    "            \"recall\": recall\n",
    "        }\n",
    "        print(f\"{err_t} || {err_R} || {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f65e60bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>,\n",
      "            {'hl': {'hl': {'err_R': 11.502983865023385,\n",
      "                           'err_t': 23.41761107951227,\n",
      "                           'recall': 0.5967545638945233},\n",
      "                    'ios': {'err_R': 24.221444273743796,\n",
      "                            'err_t': 20.0216016632602,\n",
      "                            'recall': 0.6042624320936063},\n",
      "                    'spot': {'err_R': 43.63841696276854,\n",
      "                             'err_t': 37.809824171246106,\n",
      "                             'recall': 0.35447921131590227}},\n",
      "             'ios': {'hl': {'err_R': 31.47766424253346,\n",
      "                            'err_t': 26.616537855635134,\n",
      "                            'recall': 0.5100638193421698},\n",
      "                     'ios': {'err_R': 12.126706498170027,\n",
      "                             'err_t': 13.128612865919482,\n",
      "                             'recall': 0.7906348491670419},\n",
      "                     'spot': {'err_R': 50.03590103895045,\n",
      "                              'err_t': 38.88336147669856,\n",
      "                              'recall': 0.3411140583554377}},\n",
      "             'spot': {'hl': {'err_R': 55.30179899892104,\n",
      "                             'err_t': 39.011980260039365,\n",
      "                             'recall': 0.26319005907516807},\n",
      "                      'ios': {'err_R': 50.63351825306861,\n",
      "                              'err_t': 33.868271722203225,\n",
      "                              'recall': 0.32345469940728194},\n",
      "                      'spot': {'err_R': 9.90163028191319,\n",
      "                               'err_t': 28.67325204969719,\n",
      "                               'recall': 0.5274418604651163}}})\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd0fced8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ios         hl       spot \n",
      "   ios     0.7906     0.5101     0.3411 \n",
      "    hl     0.6043     0.5968     0.3545 \n",
      "  spot     0.3235     0.2632     0.5274 \n"
     ]
    }
   ],
   "source": [
    "def show_matrix(results):\n",
    "    # Get all labels\n",
    "    labels = list(results.keys())\n",
    "\n",
    "    # Print header\n",
    "    print(f\"{'':>6}\", end=' ')\n",
    "    for col in labels:\n",
    "        print(f\"{col:>10}\", end=' ')\n",
    "    print()\n",
    "\n",
    "    # Print rows\n",
    "    for row in labels:\n",
    "        print(f\"{row:>6}\", end=' ')\n",
    "        for col in labels:\n",
    "            value = results[row][col]['recall']\n",
    "            print(f\"{value:10.4f}\", end=' ')\n",
    "        print()\n",
    "\n",
    "show_matrix(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b6e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Python dependencies...\n",
      "Dependencies OK\n",
      "You are running with parameters: \n",
      "  Capture: ./capture\n",
      "  Output: ./capture/evaluation_results\n",
      "  Benchmarking dir: long/benchmarking_results\n",
      "  Local feature method: superpoint\n",
      "  Matching method: lightglue\n",
      "  Global feature method: megaloc\n",
      "  Scenes: arche_d2\n",
      "  Devices map: ios hl spot\n",
      "  Devices query: ios hl spot\n",
      "  Position threshold: 0.5 meters\n",
      "  Rotation threshold: 5 degrees\n",
      "Running evaluation...\n",
      "Starting cross-device pose estimation evaluation\n",
      "Configuration:\n",
      "  Capture dir: ./capture\n",
      "  Benchmarking dir: long/benchmarking_results\n",
      "  Local feature method: superpoint\n",
      "  Matching method: lightglue\n",
      "  Global feature method: megaloc\n",
      "  Scenes: ['arche_d2']\n",
      "  Map devices: ['ios', 'hl', 'spot']\n",
      "  Query devices: ['ios', 'hl', 'spot']\n",
      "  Position threshold: 0.5\n",
      "  Rotation threshold: 5.0\n",
      "\n",
      "Processing scene: arche_d2\n",
      "Evaluating arche_d2: ios query vs ios map\n",
      "Evaluating arche_d2: ios query vs hl map\n",
      "Evaluating arche_d2: ios query vs spot map\n",
      "Evaluating arche_d2: hl query vs ios map\n",
      "Evaluating arche_d2: hl query vs hl map\n",
      "Evaluating arche_d2: hl query vs spot map\n",
      "Evaluating arche_d2: spot query vs ios map\n",
      "Evaluating arche_d2: spot query vs hl map\n",
      "Evaluating arche_d2: spot query vs spot map\n",
      "\n",
      "Computing overall success rate matrix\n",
      "\n",
      "ARCHE_D2 Success Rate Matrix\n",
      "----------------------------\n",
      "Query\\Map   IOS         HL          SPOT        \n",
      "------------------------------------------------\n",
      "IOS            95.58%      83.63%      56.89%   \n",
      "HL             98.86%     100.00%      84.09%   \n",
      "SPOT          100.00%      96.38%     100.00%   \n",
      "\n",
      "OVERALL Success Rate Matrix\n",
      "---------------------------\n",
      "Query\\Map   IOS         HL          SPOT        \n",
      "------------------------------------------------\n",
      "IOS            95.58%      83.63%      56.89%   \n",
      "HL             98.86%     100.00%      84.09%   \n",
      "SPOT          100.00%      96.38%     100.00%   \n",
      "\n",
      "Results saved to ./capture/evaluation_results/long/benchmarking_results\n",
      "\n",
      "Evaluation completed successfully!\n",
      "\n",
      "Evaluation completed!\n",
      "Results saved to: ./capture/evaluation_results\n"
     ]
    }
   ],
   "source": [
    "!cd ~/Workspace/crocodl-benchmark && export CAPTURE_DIR=./capture && bash ./evaluate/evaluate.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21218bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92290294",
   "metadata": {},
   "outputs": [],
   "source": [
    "EST_POSES_COLOR = [255, 0, 0]\n",
    "TRAJ_COLOR = [0, 255, 0]\n",
    "ALM_TRAJ_COLOR = [0, 0, 255]\n",
    "\n",
    "def visualize_poses(query_device, map_device):\n",
    "    import sys\n",
    "    import os\n",
    "\n",
    "    # Add project root to path\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "    if project_root not in sys.path:\n",
    "        sys.path.insert(0, project_root)\n",
    "        \n",
    "    from visualize.cam_pose_visualizer import CamPoseVisualizer, load_gt_and_est_poses\n",
    "\n",
    "    visualizer = CamPoseVisualizer()\n",
    "    \n",
    "    est_poses_path = f\"estimate_pose/{query_device}_query/{map_device}_map/est_poses.txt\"\n",
    "    traj_path = f'/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{query_device}_query/trajectories.txt'\n",
    "    alm_traj_path = f'/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{query_device}_query/proc/alignment_trajectories.txt'\n",
    "    sensors_path = f'/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{query_device}_query/sensors.txt'\n",
    "    rigs_path = None if query_device == 'ios' else f'/home/long/Workspace/crocodl-benchmark/capture/ARCHE_D2/sessions/{query_device}_query/rigs.txt'\n",
    "    est_poses, traj = load_gt_and_est_poses(est_poses_path, traj_path, sensors_path, rigs_path, EST_POSES_COLOR, TRAJ_COLOR)\n",
    "    est_poses, alm_traj = load_gt_and_est_poses(est_poses_path, alm_traj_path, sensors_path, rigs_path, EST_POSES_COLOR, ALM_TRAJ_COLOR)\n",
    "    \n",
    "    visualizer.visualize(est_poses + traj + alm_traj)\n",
    "    \n",
    "# visualize_poses(query_device, map_device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "croco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
